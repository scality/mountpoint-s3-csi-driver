NAMESPACE                  LAST SEEN   TYPE      REASON                    OBJECT                                                            MESSAGE
default                    3m43s       Normal    Starting                  node/helm-test-cluster-control-plane
kube-system                3m56s       Normal    Pulled                    pod/kube-scheduler-helm-test-cluster-control-plane                Container image "registry.k8s.io/kube-scheduler:v1.32.0" already present on machine
default                    3m56s       Normal    NodeAllocatableEnforced   node/helm-test-cluster-control-plane                              Updated Node Allocatable limit across pods
default                    3m56s       Normal    NodeHasSufficientPID      node/helm-test-cluster-control-plane                              Node helm-test-cluster-control-plane status is now: NodeHasSufficientPID
default                    3m56s       Normal    NodeHasNoDiskPressure     node/helm-test-cluster-control-plane                              Node helm-test-cluster-control-plane status is now: NodeHasNoDiskPressure
default                    3m56s       Normal    NodeHasSufficientMemory   node/helm-test-cluster-control-plane                              Node helm-test-cluster-control-plane status is now: NodeHasSufficientMemory
kube-system                3m56s       Normal    Pulled                    pod/kube-apiserver-helm-test-cluster-control-plane                Container image "registry.k8s.io/kube-apiserver:v1.32.0" already present on machine
kube-system                3m56s       Normal    Pulled                    pod/kube-controller-manager-helm-test-cluster-control-plane       Container image "registry.k8s.io/kube-controller-manager:v1.32.0" already present on machine
kube-system                3m56s       Normal    Pulled                    pod/etcd-helm-test-cluster-control-plane                          Container image "registry.k8s.io/etcd:3.5.16-0" already present on machine
kube-system                3m55s       Normal    Created                   pod/kube-controller-manager-helm-test-cluster-control-plane       Created container: kube-controller-manager
kube-system                3m55s       Normal    Started                   pod/kube-controller-manager-helm-test-cluster-control-plane       Started container kube-controller-manager
kube-system                3m55s       Normal    Started                   pod/kube-scheduler-helm-test-cluster-control-plane                Started container kube-scheduler
kube-system                3m55s       Normal    Created                   pod/kube-apiserver-helm-test-cluster-control-plane                Created container: kube-apiserver
kube-system                3m55s       Normal    Started                   pod/kube-apiserver-helm-test-cluster-control-plane                Started container kube-apiserver
kube-system                3m55s       Normal    Created                   pod/kube-scheduler-helm-test-cluster-control-plane                Created container: kube-scheduler
kube-system                3m54s       Normal    Started                   pod/etcd-helm-test-cluster-control-plane                          Started container etcd
kube-system                3m54s       Normal    Created                   pod/etcd-helm-test-cluster-control-plane                          Created container: etcd
default                    3m50s       Normal    NodeHasSufficientPID      node/helm-test-cluster-control-plane                              Node helm-test-cluster-control-plane status is now: NodeHasSufficientPID
default                    3m50s       Normal    Starting                  node/helm-test-cluster-control-plane                              Starting kubelet.
default                    3m50s       Normal    NodeAllocatableEnforced   node/helm-test-cluster-control-plane                              Updated Node Allocatable limit across pods
default                    3m50s       Normal    NodeHasSufficientMemory   node/helm-test-cluster-control-plane                              Node helm-test-cluster-control-plane status is now: NodeHasSufficientMemory
default                    3m50s       Normal    NodeHasNoDiskPressure     node/helm-test-cluster-control-plane                              Node helm-test-cluster-control-plane status is now: NodeHasNoDiskPressure
kube-system                3m49s       Normal    LeaderElection            lease/kube-controller-manager                                     helm-test-cluster-control-plane_77f7495e-78c9-4b49-83a4-6cc5e95c32e8 became leader
kube-system                3m48s       Normal    LeaderElection            lease/kube-scheduler                                              helm-test-cluster-control-plane_1cdead3f-f1fb-4de6-9e9d-9a54ee794f6a became leader
default                    3m45s       Normal    RegisteredNode            node/helm-test-cluster-control-plane                              Node helm-test-cluster-control-plane event: Registered Node helm-test-cluster-control-plane in Controller
kube-system                3m44s       Normal    SuccessfulCreate          daemonset/kube-proxy                                              Created pod: kube-proxy-j7rrw
kube-system                3m44s       Warning   FailedMount               pod/kube-proxy-j7rrw                                              MountVolume.SetUp failed for volume "kube-api-access-6kncc" : configmap "kube-root-ca.crt" not found
kube-system                3m44s       Normal    SuccessfulCreate          daemonset/kindnet                                                 Created pod: kindnet-cx4hx
kube-system                3m44s       Normal    ScalingReplicaSet         deployment/coredns                                                Scaled up replica set coredns-668d6bf9bc from 0 to 2
kube-system                3m44s       Warning   FailedMount               pod/kindnet-cx4hx                                                 MountVolume.SetUp failed for volume "kube-api-access-wrnqf" : configmap "kube-root-ca.crt" not found
kube-system                3m44s       Normal    Scheduled                 pod/kindnet-cx4hx                                                 Successfully assigned kube-system/kindnet-cx4hx to helm-test-cluster-control-plane
local-path-storage         3m44s       Normal    ScalingReplicaSet         deployment/local-path-provisioner                                 Scaled up replica set local-path-provisioner-58cc7856b6 from 0 to 1
kube-system                3m44s       Normal    Scheduled                 pod/kube-proxy-j7rrw                                              Successfully assigned kube-system/kube-proxy-j7rrw to helm-test-cluster-control-plane
kube-system                3m43s       Normal    Started                   pod/kube-proxy-j7rrw                                              Started container kube-proxy
kube-system                3m43s       Warning   FailedScheduling          pod/coredns-668d6bf9bc-fgch8                                      0/1 nodes are available: 1 node(s) had untolerated taint {node.kubernetes.io/not-ready: }. preemption: 0/1 nodes are available: 1 Preemption is not helpful for scheduling.
local-path-storage         3m43s       Normal    SuccessfulCreate          replicaset/local-path-provisioner-58cc7856b6                      Created pod: local-path-provisioner-58cc7856b6-pvzps
kube-system                3m43s       Normal    Pulled                    pod/kindnet-cx4hx                                                 Container image "docker.io/kindest/kindnetd:v20241212-9f82dd49" already present on machine
kube-system                3m43s       Normal    Created                   pod/kindnet-cx4hx                                                 Created container: kindnet-cni
kube-system                3m43s       Warning   FailedScheduling          pod/coredns-668d6bf9bc-hlq76                                      0/1 nodes are available: 1 node(s) had untolerated taint {node.kubernetes.io/not-ready: }. preemption: 0/1 nodes are available: 1 Preemption is not helpful for scheduling.
kube-system                3m43s       Normal    SuccessfulCreate          replicaset/coredns-668d6bf9bc                                     Created pod: coredns-668d6bf9bc-fgch8
kube-system                3m43s       Normal    SuccessfulCreate          replicaset/coredns-668d6bf9bc                                     Created pod: coredns-668d6bf9bc-hlq76
kube-system                3m43s       Normal    Pulled                    pod/kube-proxy-j7rrw                                              Container image "registry.k8s.io/kube-proxy:v1.32.0" already present on machine
local-path-storage         3m43s       Warning   FailedScheduling          pod/local-path-provisioner-58cc7856b6-pvzps                       0/1 nodes are available: 1 node(s) had untolerated taint {node.kubernetes.io/not-ready: }. preemption: 0/1 nodes are available: 1 Preemption is not helpful for scheduling.
kube-system                3m43s       Normal    Created                   pod/kube-proxy-j7rrw                                              Created container: kube-proxy
kube-system                3m42s       Normal    Started                   pod/kindnet-cx4hx                                                 Started container kindnet-cni
default                    3m32s       Normal    NodeReady                 node/helm-test-cluster-control-plane                              Node helm-test-cluster-control-plane status is now: NodeReady
kube-system                3m32s       Normal    Scheduled                 pod/coredns-668d6bf9bc-hlq76                                      Successfully assigned kube-system/coredns-668d6bf9bc-hlq76 to helm-test-cluster-control-plane
kube-system                3m32s       Normal    Scheduled                 pod/coredns-668d6bf9bc-fgch8                                      Successfully assigned kube-system/coredns-668d6bf9bc-fgch8 to helm-test-cluster-control-plane
local-path-storage         3m32s       Normal    Scheduled                 pod/local-path-provisioner-58cc7856b6-pvzps                       Successfully assigned local-path-storage/local-path-provisioner-58cc7856b6-pvzps to helm-test-cluster-control-plane
kube-system                3m31s       Normal    Pulled                    pod/coredns-668d6bf9bc-fgch8                                      Container image "registry.k8s.io/coredns/coredns:v1.11.3" already present on machine
local-path-storage         3m31s       Normal    Pulled                    pod/local-path-provisioner-58cc7856b6-pvzps                       Container image "docker.io/kindest/local-path-provisioner:v20241212-8ac705d0" already present on machine
kube-system                3m31s       Normal    Pulled                    pod/coredns-668d6bf9bc-hlq76                                      Container image "registry.k8s.io/coredns/coredns:v1.11.3" already present on machine
kube-system                3m30s       Normal    Created                   pod/coredns-668d6bf9bc-fgch8                                      Created container: coredns
kube-system                3m30s       Normal    Started                   pod/coredns-668d6bf9bc-fgch8                                      Started container coredns
kube-system                3m30s       Normal    Started                   pod/coredns-668d6bf9bc-hlq76                                      Started container coredns
kube-system                3m30s       Normal    Created                   pod/coredns-668d6bf9bc-hlq76                                      Created container: coredns
local-path-storage         3m30s       Normal    Created                   pod/local-path-provisioner-58cc7856b6-pvzps                       Created container: local-path-provisioner
local-path-storage         3m30s       Normal    Started                   pod/local-path-provisioner-58cc7856b6-pvzps                       Started container local-path-provisioner
kube-system                3m6s        Normal    SuccessfulDelete          replicaset/coredns-668d6bf9bc                                     Deleted pod: coredns-668d6bf9bc-hlq76
kube-system                3m6s        Normal    Scheduled                 pod/coredns-6f5f77fcb7-fdx4j                                      Successfully assigned kube-system/coredns-6f5f77fcb7-fdx4j to helm-test-cluster-control-plane
kube-system                3m6s        Normal    ScalingReplicaSet         deployment/coredns                                                Scaled up replica set coredns-6f5f77fcb7 from 1 to 2
kube-system                3m6s        Normal    ScalingReplicaSet         deployment/coredns                                                Scaled down replica set coredns-668d6bf9bc from 2 to 1
kube-system                3m6s        Normal    ScalingReplicaSet         deployment/coredns                                                Scaled up replica set coredns-6f5f77fcb7 from 0 to 1
kube-system                3m6s        Normal    SuccessfulCreate          replicaset/coredns-6f5f77fcb7                                     Created pod: coredns-6f5f77fcb7-fdx4j
kube-system                3m6s        Normal    SuccessfulCreate          replicaset/coredns-6f5f77fcb7                                     Created pod: coredns-6f5f77fcb7-6jtst
kube-system                3m6s        Normal    Killing                   pod/coredns-668d6bf9bc-hlq76                                      Stopping container coredns
kube-system                3m6s        Normal    Scheduled                 pod/coredns-6f5f77fcb7-6jtst                                      Successfully assigned kube-system/coredns-6f5f77fcb7-6jtst to helm-test-cluster-control-plane
kube-system                3m6s        Normal    Pulled                    pod/coredns-6f5f77fcb7-6jtst                                      Container image "registry.k8s.io/coredns/coredns:v1.11.3" already present on machine
kube-system                3m5s        Normal    Started                   pod/coredns-6f5f77fcb7-6jtst                                      Started container coredns
default                    3m5s        Normal    Scheduled                 pod/dns-test                                                      Successfully assigned default/dns-test to helm-test-cluster-control-plane
kube-system                3m5s        Normal    Created                   pod/coredns-6f5f77fcb7-6jtst                                      Created container: coredns
kube-system                3m5s        Normal    Pulled                    pod/coredns-6f5f77fcb7-fdx4j                                      Container image "registry.k8s.io/coredns/coredns:v1.11.3" already present on machine
kube-system                3m5s        Normal    Created                   pod/coredns-6f5f77fcb7-fdx4j                                      Created container: coredns
kube-system                3m5s        Normal    SuccessfulDelete          replicaset/coredns-668d6bf9bc                                     Deleted pod: coredns-668d6bf9bc-fgch8
kube-system                3m5s        Normal    ScalingReplicaSet         deployment/coredns                                                Scaled down replica set coredns-668d6bf9bc from 1 to 0
kube-system                3m5s        Normal    Started                   pod/coredns-6f5f77fcb7-fdx4j                                      Started container coredns
kube-system                3m5s        Normal    Killing                   pod/coredns-668d6bf9bc-fgch8                                      Stopping container coredns
default                    3m5s        Normal    Pulling                   pod/dns-test                                                      Pulling image "busybox:1.28"
default                    3m3s        Normal    Started                   pod/dns-test                                                      Started container dns-test
default                    3m3s        Normal    Created                   pod/dns-test                                                      Created container: dns-test
default                    3m3s        Normal    Pulled                    pod/dns-test                                                      Successfully pulled image "busybox:1.28" in 1.886s (1.886s including waiting). Image size: 727869 bytes.
kube-system                2m43s       Normal    Scheduled                 pod/s3-csi-node-nkx5d                                             Successfully assigned kube-system/s3-csi-node-nkx5d to helm-test-cluster-control-plane
kube-system                2m43s       Normal    Started                   pod/s3-csi-controller-84f6bdfd58-7cpmf                            Started container s3-pod-reconciler
kube-system                2m43s       Normal    SuccessfulCreate          daemonset/s3-csi-node                                             Created pod: s3-csi-node-nkx5d
kube-system                2m43s       Normal    Scheduled                 pod/s3-csi-controller-84f6bdfd58-7cpmf                            Successfully assigned kube-system/s3-csi-controller-84f6bdfd58-7cpmf to helm-test-cluster-control-plane
kube-system                2m43s       Normal    Pulled                    pod/s3-csi-controller-84f6bdfd58-7cpmf                            Container image "ghcr.io/scality/mountpoint-s3-csi-driver:ec17ad4f838a7cec5579099a9f46d84d4e47b333" already present on machine
kube-system                2m43s       Normal    Created                   pod/s3-csi-controller-84f6bdfd58-7cpmf                            Created container: s3-csi-controller
kube-system                2m43s       Normal    Started                   pod/s3-csi-controller-84f6bdfd58-7cpmf                            Started container s3-csi-controller
kube-system                2m43s       Normal    Pulled                    pod/s3-csi-controller-84f6bdfd58-7cpmf                            Container image "ghcr.io/scality/mountpoint-s3-csi-driver:ec17ad4f838a7cec5579099a9f46d84d4e47b333" already present on machine
kube-system                2m43s       Normal    Created                   pod/s3-csi-controller-84f6bdfd58-7cpmf                            Created container: s3-pod-reconciler
kube-system                2m43s       Normal    Created                   pod/s3-csi-node-nkx5d                                             Created container: s3-plugin
kube-system                2m43s       Normal    Pulling                   pod/s3-csi-controller-84f6bdfd58-7cpmf                            Pulling image "ghcr.io/scality/mountpoint-s3-csi-driver/csi-provisioner:v5.3.0"
kube-system                2m43s       Normal    Pulled                    pod/s3-csi-node-nkx5d                                             Container image "ghcr.io/scality/mountpoint-s3-csi-driver:ec17ad4f838a7cec5579099a9f46d84d4e47b333" already present on machine
kube-system                2m43s       Normal    Started                   pod/s3-csi-node-nkx5d                                             Started container s3-plugin
kube-system                2m43s       Normal    Pulling                   pod/s3-csi-node-nkx5d                                             Pulling image "ghcr.io/scality/mountpoint-s3-csi-driver/csi-node-driver-registrar:v2.14.0"
kube-system                2m43s       Normal    SuccessfulCreate          replicaset/s3-csi-controller-84f6bdfd58                           Created pod: s3-csi-controller-84f6bdfd58-7cpmf
kube-system                2m43s       Normal    ScalingReplicaSet         deployment/s3-csi-controller                                      Scaled up replica set s3-csi-controller-84f6bdfd58 from 0 to 1
kube-system                2m40s       Normal    Pulled                    pod/s3-csi-node-nkx5d                                             Successfully pulled image "ghcr.io/scality/mountpoint-s3-csi-driver/csi-node-driver-registrar:v2.14.0" in 3.083s (3.083s including waiting). Image size: 15579380 bytes.
kube-system                2m40s       Normal    Created                   pod/s3-csi-node-nkx5d                                             Created container: node-driver-registrar
kube-system                2m39s       Normal    Pulling                   pod/s3-csi-node-nkx5d                                             Pulling image "ghcr.io/scality/mountpoint-s3-csi-driver/livenessprobe:v2.16.0"
kube-system                2m39s       Normal    Started                   pod/s3-csi-node-nkx5d                                             Started container node-driver-registrar
kube-system                2m37s       Normal    Started                   pod/s3-csi-controller-84f6bdfd58-7cpmf                            Started container csi-provisioner
kube-system                2m37s       Normal    Created                   pod/s3-csi-controller-84f6bdfd58-7cpmf                            Created container: csi-provisioner
kube-system                2m37s       Normal    Pulled                    pod/s3-csi-controller-84f6bdfd58-7cpmf                            Successfully pulled image "ghcr.io/scality/mountpoint-s3-csi-driver/csi-provisioner:v5.3.0" in 2.701s (5.674s including waiting). Image size: 35709312 bytes.
kube-system                2m35s       Normal    Created                   pod/s3-csi-node-nkx5d                                             Created container: liveness-probe
kube-system                2m35s       Normal    Pulled                    pod/s3-csi-node-nkx5d                                             Successfully pulled image "ghcr.io/scality/mountpoint-s3-csi-driver/livenessprobe:v2.16.0" in 2.149s (4.758s including waiting). Image size: 15557083 bytes.
kube-system                2m35s       Normal    Started                   pod/s3-csi-node-nkx5d                                             Started container liveness-probe
volume-1120                2m31s       Normal    ProvisioningSucceeded     persistentvolumeclaim/s3.csi.scality.comsr5nc                     Successfully provisioned volume pvc-ed6ac51f-1a8b-4e00-9132-695ea2fa6bb6
volume-1120                2m31s       Normal    Provisioning              persistentvolumeclaim/s3.csi.scality.comsr5nc                     External provisioner is provisioning volume for claim "volume-1120/s3.csi.scality.comsr5nc"
volume-1120                2m31s       Normal    ExternalProvisioning      persistentvolumeclaim/s3.csi.scality.comsr5nc                     Waiting for a volume to be created either by the external provisioner 's3.csi.scality.com' or manually by the system administrator. If volume creation is delayed, please verify that the provisioner is running and correctly registered.
volume-3903                2m31s       Warning   ProvisioningFailed        persistentvolumeclaim/pvc-xcdzz                                   storageclass.storage.k8s.io "volume-3903" not found
mount-s3                   2m29s       Normal    Scheduled                 pod/mp-7574e21ee3530a31c680a30cea91d393f8f1abf6dd8f9d36d9fada20   Successfully assigned mount-s3/mp-7574e21ee3530a31c680a30cea91d393f8f1abf6dd8f9d36d9fada20 to helm-test-cluster-control-plane
cache-2772                 2m29s       Normal    Scheduled                 pod/pvc-tester-dwhq2                                              Successfully assigned cache-2772/pvc-tester-dwhq2 to helm-test-cluster-control-plane
mount-s3                   2m29s       Normal    Scheduled                 pod/mp-6094027646566d3f9a94fa4793209d8f89ccb09067362486a6f6dc50   Successfully assigned mount-s3/mp-6094027646566d3f9a94fa4793209d8f89ccb09067362486a6f6dc50 to helm-test-cluster-control-plane
volume-3903                2m29s       Normal    Scheduled                 pod/s3-injector                                                   Successfully assigned volume-3903/s3-injector to helm-test-cluster-control-plane
cache-6176                 2m29s       Normal    Scheduled                 pod/pvc-tester-tsdmc                                              Successfully assigned cache-6176/pvc-tester-tsdmc to helm-test-cluster-control-plane
volume-1120                2m29s       Normal    Scheduled                 pod/s3-injector                                                   Successfully assigned volume-1120/s3-injector to helm-test-cluster-control-plane
mount-s3                   2m29s       Normal    Scheduled                 pod/mp-9b6c6c8aeead40f8164a2e67a085886b769d7b44015f99e758aea281   Successfully assigned mount-s3/mp-9b6c6c8aeead40f8164a2e67a085886b769d7b44015f99e758aea281 to helm-test-cluster-control-plane
mount-s3                   2m29s       Normal    Scheduled                 pod/mp-afe8f18f9fb99bb5d149ca93619869a0fb9cefe5de1246f31b9eb9c6   Successfully assigned mount-s3/mp-afe8f18f9fb99bb5d149ca93619869a0fb9cefe5de1246f31b9eb9c6 to helm-test-cluster-control-plane
mount-s3                   2m26s       Normal    Scheduled                 pod/mp-6a85bc6e5df680f35e4431d67874b4ae3e46899cc68459346fab9e73   Successfully assigned mount-s3/mp-6a85bc6e5df680f35e4431d67874b4ae3e46899cc68459346fab9e73 to helm-test-cluster-control-plane
s3-advanced-patterns-610   2m15s       Normal    WaitForFirstConsumer      persistentvolumeclaim/wait-pvc-07c7e39e                           waiting for first consumer to be created before binding
cache-9720                 2m13s       Normal    Scheduled                 pod/pvc-tester-zl2k5                                              Successfully assigned cache-9720/pvc-tester-zl2k5 to helm-test-cluster-control-plane
mount-s3                   2m13s       Normal    Scheduled                 pod/mp-882387e76a89724d8a9549f945f963f64f924af00ea7a32eaa6fc796   Successfully assigned mount-s3/mp-882387e76a89724d8a9549f945f963f64f924af00ea7a32eaa6fc796 to helm-test-cluster-control-plane
s3-advanced-patterns-610   2m1s        Normal    ProvisioningSucceeded     persistentvolumeclaim/wait-pvc-07c7e39e                           Successfully provisioned volume pvc-5d062f4f-1813-43a2-8ec0-68213b6a3c21
s3-advanced-patterns-610   2m1s        Normal    Provisioning              persistentvolumeclaim/wait-pvc-07c7e39e                           External provisioner is provisioning volume for claim "s3-advanced-patterns-610/wait-pvc-07c7e39e"
s3-advanced-patterns-610   2m1s        Normal    ExternalProvisioning      persistentvolumeclaim/wait-pvc-07c7e39e                           Waiting for a volume to be created either by the external provisioner 's3.csi.scality.com' or manually by the system administrator. If volume creation is delayed, please verify that the provisioner is running and correctly registered.
mount-s3                   2m          Normal    Created                   pod/mp-6c4ed57bf013246d0f03369a5d8425dba1897bd3de27aeb6c0ce0bf0   Created container: mountpoint
s3-advanced-patterns-610   2m          Normal    Scheduled                 pod/wait-pod-e3a3b9dc                                             Successfully assigned s3-advanced-patterns-610/wait-pod-e3a3b9dc to helm-test-cluster-control-plane
mount-s3                   2m          Normal    Scheduled                 pod/mp-6c4ed57bf013246d0f03369a5d8425dba1897bd3de27aeb6c0ce0bf0   Successfully assigned mount-s3/mp-6c4ed57bf013246d0f03369a5d8425dba1897bd3de27aeb6c0ce0bf0 to helm-test-cluster-control-plane
mount-s3                   2m          Normal    Pulled                    pod/mp-6c4ed57bf013246d0f03369a5d8425dba1897bd3de27aeb6c0ce0bf0   Container image "ghcr.io/scality/mountpoint-s3-csi-driver:ec17ad4f838a7cec5579099a9f46d84d4e47b333" already present on machine
mount-s3                   2m          Normal    Started                   pod/mp-6c4ed57bf013246d0f03369a5d8425dba1897bd3de27aeb6c0ce0bf0   Started container mountpoint
mount-s3                   89s         Normal    Created                   pod/mp-159b10046d4e6e59585206321e043d7e26ef27ddda8259914b58fa7b   Created container: mountpoint
mount-s3                   89s         Normal    Pulled                    pod/mp-159b10046d4e6e59585206321e043d7e26ef27ddda8259914b58fa7b   Container image "ghcr.io/scality/mountpoint-s3-csi-driver:ec17ad4f838a7cec5579099a9f46d84d4e47b333" already present on machine
mount-s3                   89s         Normal    Scheduled                 pod/mp-159b10046d4e6e59585206321e043d7e26ef27ddda8259914b58fa7b   Successfully assigned mount-s3/mp-159b10046d4e6e59585206321e043d7e26ef27ddda8259914b58fa7b to helm-test-cluster-control-plane
mount-s3                   89s         Normal    Started                   pod/mp-159b10046d4e6e59585206321e043d7e26ef27ddda8259914b58fa7b   Started container mountpoint
credentials-9803           89s         Normal    Scheduled                 pod/pvc-tester-67jbd                                              Successfully assigned credentials-9803/pvc-tester-67jbd to helm-test-cluster-control-plane
s3-advanced-patterns-610   56s         Warning   FailedMount               pod/wait-pod-e3a3b9dc                                             MountVolume.SetUp failed for volume "pvc-5d062f4f-1813-43a2-8ec0-68213b6a3c21" : rpc error: code = Internal desc = Could not mount "csi-s3-51eeefbb-2468-4110-9200-2666312be6aa" at "/var/lib/kubelet/pods/1243b6af-14c2-4680-9ec8-239559f6722d/volumes/kubernetes.io~csi/pvc-5d062f4f-1813-43a2-8ec0-68213b6a3c21/mount": failed to wait for MountpointS3PodAttachment for "/var/lib/kubelet/pods/1243b6af-14c2-4680-9ec8-239559f6722d/volumes/kubernetes.io~csi/pvc-5d062f4f-1813-43a2-8ec0-68213b6a3c21/mount": field label not supported: spec.authenticationSource. You can see the controller logs by running `kubectl logs -n kube-system -lapp=s3-csi-controller`.
mount-s3                   28s         Normal    Created                   pod/mp-7574e21ee3530a31c680a30cea91d393f8f1abf6dd8f9d36d9fada20   Created container: mountpoint
mount-s3                   28s         Normal    Started                   pod/mp-6094027646566d3f9a94fa4793209d8f89ccb09067362486a6f6dc50   Started container mountpoint
mount-s3                   28s         Normal    Started                   pod/mp-afe8f18f9fb99bb5d149ca93619869a0fb9cefe5de1246f31b9eb9c6   Started container mountpoint
mount-s3                   28s         Normal    Started                   pod/mp-7574e21ee3530a31c680a30cea91d393f8f1abf6dd8f9d36d9fada20   Started container mountpoint
mount-s3                   28s         Normal    Pulled                    pod/mp-7574e21ee3530a31c680a30cea91d393f8f1abf6dd8f9d36d9fada20   Container image "ghcr.io/scality/mountpoint-s3-csi-driver:ec17ad4f838a7cec5579099a9f46d84d4e47b333" already present on machine
mount-s3                   28s         Normal    Pulled                    pod/mp-6094027646566d3f9a94fa4793209d8f89ccb09067362486a6f6dc50   Container image "ghcr.io/scality/mountpoint-s3-csi-driver:ec17ad4f838a7cec5579099a9f46d84d4e47b333" already present on machine
mount-s3                   28s         Normal    Created                   pod/mp-6094027646566d3f9a94fa4793209d8f89ccb09067362486a6f6dc50   Created container: mountpoint
mount-s3                   28s         Normal    Created                   pod/mp-afe8f18f9fb99bb5d149ca93619869a0fb9cefe5de1246f31b9eb9c6   Created container: mountpoint
mount-s3                   28s         Normal    Pulled                    pod/mp-afe8f18f9fb99bb5d149ca93619869a0fb9cefe5de1246f31b9eb9c6   Container image "ghcr.io/scality/mountpoint-s3-csi-driver:ec17ad4f838a7cec5579099a9f46d84d4e47b333" already present on machine
mount-s3                   28s         Normal    Pulled                    pod/mp-9b6c6c8aeead40f8164a2e67a085886b769d7b44015f99e758aea281   Container image "ghcr.io/scality/mountpoint-s3-csi-driver:ec17ad4f838a7cec5579099a9f46d84d4e47b333" already present on machine
mount-s3                   28s         Normal    Created                   pod/mp-9b6c6c8aeead40f8164a2e67a085886b769d7b44015f99e758aea281   Created container: mountpoint
mount-s3                   28s         Normal    Started                   pod/mp-9b6c6c8aeead40f8164a2e67a085886b769d7b44015f99e758aea281   Started container mountpoint
mount-s3                   25s         Normal    Created                   pod/mp-6a85bc6e5df680f35e4431d67874b4ae3e46899cc68459346fab9e73   Created container: mountpoint
mount-s3                   25s         Normal    Pulled                    pod/mp-6a85bc6e5df680f35e4431d67874b4ae3e46899cc68459346fab9e73   Container image "ghcr.io/scality/mountpoint-s3-csi-driver:ec17ad4f838a7cec5579099a9f46d84d4e47b333" already present on machine
mount-s3                   25s         Normal    Started                   pod/mp-6a85bc6e5df680f35e4431d67874b4ae3e46899cc68459346fab9e73   Started container mountpoint
credentials-9803           25s         Warning   FailedMount               pod/pvc-tester-67jbd                                              MountVolume.SetUp failed for volume "s3-e2e-pv-ae989c45-3114-4a17-9b31-e019f99153b0" : rpc error: code = Internal desc = Could not mount "s3-csi-k8s-e2e-7b97gdfb9dsxvjpddlfgmdl8ps8r9zs49zcbg5hjf69gks9m" at "/var/lib/kubelet/pods/4b076a0b-7a4d-49d6-b590-669c9e25accd/volumes/kubernetes.io~csi/s3-e2e-pv-ae989c45-3114-4a17-9b31-e019f99153b0/mount": failed to wait for MountpointS3PodAttachment for "/var/lib/kubelet/pods/4b076a0b-7a4d-49d6-b590-669c9e25accd/volumes/kubernetes.io~csi/s3-e2e-pv-ae989c45-3114-4a17-9b31-e019f99153b0/mount": field label not supported: spec.authenticationSource. You can see the controller logs by running `kubectl logs -n kube-system -lapp=s3-csi-controller`.
cache-2772                 21s         Warning   FailedMount               pod/pvc-tester-dwhq2                                              MountVolume.SetUp failed for volume "s3-e2e-pv-9889fc2f-c808-4623-b190-7e4bcdeb4f74" : rpc error: code = Internal desc = Could not mount "s3-csi-k8s-e2e-wckmzrfgk7pn6sb2fbmws44k5n2vmx2tnjpngvnjqnnhbmfq" at "/var/lib/kubelet/pods/43cea5c5-d75d-4b6d-a669-8b9f63a8a19d/volumes/kubernetes.io~csi/s3-e2e-pv-9889fc2f-c808-4623-b190-7e4bcdeb4f74/mount": failed to wait for MountpointS3PodAttachment for "/var/lib/kubelet/pods/43cea5c5-d75d-4b6d-a669-8b9f63a8a19d/volumes/kubernetes.io~csi/s3-e2e-pv-9889fc2f-c808-4623-b190-7e4bcdeb4f74/mount": field label not supported: spec.authenticationSource. You can see the controller logs by running `kubectl logs -n kube-system -lapp=s3-csi-controller`.
volume-1120                21s         Warning   FailedMount               pod/s3-injector                                                   MountVolume.SetUp failed for volume "pvc-ed6ac51f-1a8b-4e00-9132-695ea2fa6bb6" : rpc error: code = Internal desc = Could not mount "csi-s3-56fce90b-b62b-4eb0-b3ea-fafb76b9323a" at "/var/lib/kubelet/pods/72939224-f413-49d1-b6b6-bbee9aae3f22/volumes/kubernetes.io~csi/pvc-ed6ac51f-1a8b-4e00-9132-695ea2fa6bb6/mount": failed to wait for MountpointS3PodAttachment for "/var/lib/kubelet/pods/72939224-f413-49d1-b6b6-bbee9aae3f22/volumes/kubernetes.io~csi/pvc-ed6ac51f-1a8b-4e00-9132-695ea2fa6bb6/mount": field label not supported: spec.authenticationSource. You can see the controller logs by running `kubectl logs -n kube-system -lapp=s3-csi-controller`.
volume-3903                21s         Warning   FailedMount               pod/s3-injector                                                   MountVolume.SetUp failed for volume "s3.csi.scality.com-jrq4b" : rpc error: code = Internal desc = Could not mount "s3-csi-k8s-e2e-c6c4dqwfz72d6nmggpnx986p5252nj7vwvf8zfxgxw98dmpw" at "/var/lib/kubelet/pods/4f49525f-bef6-478b-83f9-1673c510a51a/volumes/kubernetes.io~csi/s3.csi.scality.com-jrq4b/mount": failed to wait for MountpointS3PodAttachment for "/var/lib/kubelet/pods/4f49525f-bef6-478b-83f9-1673c510a51a/volumes/kubernetes.io~csi/s3.csi.scality.com-jrq4b/mount": field label not supported: spec.authenticationSource. You can see the controller logs by running `kubectl logs -n kube-system -lapp=s3-csi-controller`.
cache-6176                 21s         Warning   FailedMount               pod/pvc-tester-tsdmc                                              MountVolume.SetUp failed for volume "s3-e2e-pv-5a1ec614-7174-4db3-997e-1ad5aa6fb41b" : rpc error: code = Internal desc = Could not mount "s3-csi-k8s-e2e-rzx8ggxnxcj5btdxlf5blhx8sxkzv92hzpbgmxtjs9jw9gxm" at "/var/lib/kubelet/pods/11c6ba65-d874-46e5-8a9f-d48b9ddce169/volumes/kubernetes.io~csi/s3-e2e-pv-5a1ec614-7174-4db3-997e-1ad5aa6fb41b/mount": failed to wait for MountpointS3PodAttachment for "/var/lib/kubelet/pods/11c6ba65-d874-46e5-8a9f-d48b9ddce169/volumes/kubernetes.io~csi/s3-e2e-pv-5a1ec614-7174-4db3-997e-1ad5aa6fb41b/mount": field label not supported: spec.authenticationSource. You can see the controller logs by running `kubectl logs -n kube-system -lapp=s3-csi-controller`.
credentials-9438           14s         Normal    Scheduled                 pod/pvc-tester-7f9mh                                              Successfully assigned credentials-9438/pvc-tester-7f9mh to helm-test-cluster-control-plane
mount-s3                   14s         Normal    Created                   pod/mp-6cf8cfb7544fed74f72a401dafc06778f89669c0a8f9bef49e463381   Created container: mountpoint
mount-s3                   14s         Normal    Scheduled                 pod/mp-6cf8cfb7544fed74f72a401dafc06778f89669c0a8f9bef49e463381   Successfully assigned mount-s3/mp-6cf8cfb7544fed74f72a401dafc06778f89669c0a8f9bef49e463381 to helm-test-cluster-control-plane
mount-s3                   14s         Normal    Started                   pod/mp-6cf8cfb7544fed74f72a401dafc06778f89669c0a8f9bef49e463381   Started container mountpoint
mount-s3                   14s         Normal    Pulled                    pod/mp-6cf8cfb7544fed74f72a401dafc06778f89669c0a8f9bef49e463381   Container image "ghcr.io/scality/mountpoint-s3-csi-driver:ec17ad4f838a7cec5579099a9f46d84d4e47b333" already present on machine
mount-s3                   12s         Normal    Pulled                    pod/mp-882387e76a89724d8a9549f945f963f64f924af00ea7a32eaa6fc796   Container image "ghcr.io/scality/mountpoint-s3-csi-driver:ec17ad4f838a7cec5579099a9f46d84d4e47b333" already present on machine
mount-s3                   12s         Normal    Created                   pod/mp-882387e76a89724d8a9549f945f963f64f924af00ea7a32eaa6fc796   Created container: mountpoint
mount-s3                   12s         Normal    Started                   pod/mp-882387e76a89724d8a9549f945f963f64f924af00ea7a32eaa6fc796   Started container mountpoint
credentials-9438           6s          Warning   FailedMount               pod/pvc-tester-7f9mh                                              MountVolume.SetUp failed for volume "s3-e2e-pv-ac9eff36-d5ba-451c-b10b-a151a677bfba" : rpc error: code = Internal desc = Could not mount "s3-csi-k8s-e2e-l5hfm8zshd7mh8w5l5bkmprxrqwv8rq7qdr4xtppvbv9mh5j" at "/var/lib/kubelet/pods/de74c82e-0196-41fe-8fef-8ddb9f4c2407/volumes/kubernetes.io~csi/s3-e2e-pv-ac9eff36-d5ba-451c-b10b-a151a677bfba/mount": failed to wait for MountpointS3PodAttachment for "/var/lib/kubelet/pods/de74c82e-0196-41fe-8fef-8ddb9f4c2407/volumes/kubernetes.io~csi/s3-e2e-pv-ac9eff36-d5ba-451c-b10b-a151a677bfba/mount": field label not supported: spec.authenticationSource. You can see the controller logs by running `kubectl logs -n kube-system -lapp=s3-csi-controller`.
cache-9720                 5s          Warning   FailedMount               pod/pvc-tester-zl2k5                                              MountVolume.SetUp failed for volume "s3-e2e-pv-8166c059-6d8b-4308-a0d6-39f0993d081d" : rpc error: code = Internal desc = Could not mount "s3-csi-k8s-e2e-cv867fmkkbn4pq4c8gcr9wfdw5sd66ksnnw4wp7wzz226dzb" at "/var/lib/kubelet/pods/b1936d9d-388d-4083-96b4-56bcdf7d3711/volumes/kubernetes.io~csi/s3-e2e-pv-8166c059-6d8b-4308-a0d6-39f0993d081d/mount": failed to wait for MountpointS3PodAttachment for "/var/lib/kubelet/pods/b1936d9d-388d-4083-96b4-56bcdf7d3711/volumes/kubernetes.io~csi/s3-e2e-pv-8166c059-6d8b-4308-a0d6-39f0993d081d/mount": field label not supported: spec.authenticationSource. You can see the controller logs by running `kubectl logs -n kube-system -lapp=s3-csi-controller`.
